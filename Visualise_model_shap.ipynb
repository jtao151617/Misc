{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use /home/vr/venv_cluster\n",
    "# Test out SHAP deepExplainer for visualise saliency regions\n",
    "# reference: \n",
    "# https://shap-lrjball.readthedocs.io/en/latest/example_notebooks/deep_explainer/PyTorch%20Deep%20Explainer%20MNIST%20example.html\n",
    "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "import torch, torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision.models import resnet50, resnet18, densenet121, vgg11_bn, alexnet\n",
    "\n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "%env CUDA_VISIBLE_DEVICES=1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 2\n",
    "device = torch.device('cuda')\n",
    "num_classes = 10 # to change depend on which dataset used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backbone(backbone, castrate=True):\n",
    "    backbone = eval(f\"{backbone}()\")\n",
    "\n",
    "    if castrate:\n",
    "        backbone.output_dim = backbone.fc.in_features\n",
    "        backbone.fc = torch.nn.Identity() # no ops just forwarding the input given to it\n",
    "\n",
    "    return backbone, backbone.output_dim\n",
    "\n",
    "# during inferencing, freezing layers or feature extract, grad is not needed\n",
    "def set_parameter_requires_grad_false(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained models: resnet50, resnet18, densenet121, vgg11_bn, alexnet\n",
    "model = resnet18(pretrained=True)\n",
    "\n",
    "num_ftrs = model.fc.in_features # resnet\n",
    "#num_ftrs = model.classifier.in_features # densenet\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "#num_ftrs = model.classifier[6].in_features # vgg11_bn, alexnet\n",
    "#model.classifier[6] = nn.Linear(num_ftrs,num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet50 pretrained model by Simsiam\n",
    "model_dir ='/home/vr/simsiam_cache/simsiam-resnet50-augs-fullset-hand_0327170940.pth'\n",
    "backbone ='resnet50'  # 'resnet18_cifar_variant1' 'resnet50'\n",
    "model, dim_feature_last = get_backbone(backbone)\n",
    "save_dict = torch.load(model_dir, map_location=device)\n",
    "\n",
    "# set the strict argument to **False** in the load_state_dict() function to ignore non-matching keys\n",
    "msg = model.load_state_dict({k[9:]:v for k, v in save_dict['state_dict'].items() if k.startswith('backbone.')}, strict=True)\n",
    "print(msg)\n",
    "\n",
    "set_parameter_requires_grad_false(model)\n",
    "# Replace the last fully-connected layer\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "# model.fc = nn.Sequential(\n",
    "#    nn.Linear(dim_feature_last, 50),\n",
    "#    nn.ReLU(),\n",
    "#    nn.Dropout(),\n",
    "#    nn.Linear(50, num_classes),\n",
    "#    nn.Softmax(dim=1),\n",
    "#)\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(dim_feature_last, num_classes)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print({k[9:]:v for k, v in save_dict['state_dict'].items() if k.startswith('backbone.')})\n",
    "#print(save_dict)\n",
    "x = torch.randn(2, 2)\n",
    "print((x.unsqueeze_(0)).repeat(3,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        #print('data: {}, output: {}, output.log(): {}, target: {}'.format(data.shape, output.shape, (output.log()).shape,target.shape))\n",
    "        \n",
    "        #loss = F.nll_loss(output.log(), target)\n",
    "        loss = criterion(output, target)\n",
    "        #loss = criterion(output.log(), target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            #test_loss += F.nll_loss(output.log(), target).item() # sum up batch loss\n",
    "            #test_loss += criterion(output.log(), target).item()\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "            #print('gt:{}, pred:{}', target.view_as(pred), pred)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINST \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('mnist_data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       #transforms.Resize(224),\n",
    "                       transforms.ToTensor(),\n",
    "                       #transforms.Lambda(lambda x: x.repeat(3,1,1))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('mnist_data', train=False, transform=transforms.Compose([\n",
    "                       #transforms.Resize(224),\n",
    "                       transforms.ToTensor(),\n",
    "                       #transforms.Lambda(lambda x: x.repeat(3,1,1))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR 10\n",
    "# Image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    #transforms.Resize(224),\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    #transforms.RandomCrop(224),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../data/',\n",
    "                                             train=True, \n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../data/',\n",
    "                                            train=False, \n",
    "                                            transform=transforms.ToTensor())\n",
    "                                            #transform=transforms.Compose([transforms.Resize(224),transforms.ToTensor()]))\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "# Optimize only the classifier\n",
    "#optimizer = optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deepexplainer NOTE: ResNet50 report dimension error\n",
    "# since shuffle=True, this is a random sample of test data\n",
    "batch = next(iter(test_loader))\n",
    "images, _ = batch\n",
    "\n",
    "background = images[:100]\n",
    "test_images = images[100:103]\n",
    "\n",
    "print(test_images.shape)\n",
    "\n",
    "model = model.to('cpu')\n",
    "e = shap.DeepExplainer(model, background)\n",
    "#print(e.supports_model(model))\n",
    "shap_values = e.shap_values(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]\n",
    "test_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the feature attributions\n",
    "shap.image_plot(shap_numpy, test_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient exmplainer\n",
    "# refer to example https://shap-lrjball.readthedocs.io/en/latest/example_notebooks/gradient_explainer/Explain%20an%20Intermediate%20Layer%20of%20VGG16%20on%20ImageNet%20%28PyTorch%29.html\n",
    "\n",
    "# print(model.features.denseblock2.denselayer12.conv2) # Densenet\n",
    "\n",
    "batch = next(iter(test_loader))\n",
    "images, _ = batch\n",
    "background = images[:100]\n",
    "test_images = images[100:102]\n",
    "\n",
    "to_show = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)\n",
    "#print(to_show.shape)\n",
    "\n",
    "model = model.to('cpu')\n",
    "\n",
    "e = shap.GradientExplainer((model, model.layer3[0]), background) # resnet\n",
    "#e = shap.GradientExplainer((model, model.features[7]), background) #vgg\n",
    "shap_values,indexes = e.shap_values(test_images, ranked_outputs=2, nsamples=200)\n",
    "# plot the explanations\n",
    "shap_values = [np.swapaxes(np.swapaxes(s, 2, 3), 1, -1) for s in shap_values]\n",
    "\n",
    "shap.image_plot(shap_values, to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-studio",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
